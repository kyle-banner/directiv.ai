<!DOCTYPE html>
<html lang="en">

<head>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-SXC8XPH34V"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-SXC8XPH34V');
    </script>

    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GenAI Isn't the Problem. Your Architecture Is. | directiv.ai blog</title>
    <link rel="icon" href="/favicon.svg" type="image/svg+xml" />
    <style>
        :root {
            --bg: #0f1116;
            --panel: #141824;
            --text: #e4e6eb;
            --muted: #b9bcc3;
            --accent: #2b8eff;
            --accent-light: #5aa7ff;
            --font: "Inter", system-ui, -apple-system, sans-serif;
        }

        * {
            box-sizing: border-box;
        }

        body {
            margin: 0;
            font-family: var(--font);
            background: radial-gradient(circle at top, #151a2a, var(--bg) 45%);
            color: var(--text);
            min-height: 100vh;
            padding: 2rem;
        }

        a {
            color: var(--accent-light);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
        }

        .nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 2.5rem;
        }

        .nav a {
            font-weight: 600;
            color: var(--text);
        }

        .title {
            margin: 0 0 0.5rem;
            font-size: 2.4rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            margin: 0 0 2rem;
            color: var(--muted);
            line-height: 1.6;
        }

        .post {
            background: var(--panel);
            border: 1px solid #1f2434;
            border-radius: 1rem;
            padding: 2rem;
            margin-bottom: 2rem;
            box-shadow: 0 18px 40px rgba(0, 0, 0, 0.25);
        }

        .post-title {
            margin: 0 0 0.2rem;
            font-size: 1.8rem;
        }

        .post-meta {
            font-size: 0.95rem;
            color: var(--muted);
            margin-bottom: 1.5rem;
        }

        .post-subtitle {
            font-size: 1.05rem;
            color: var(--text);
            margin-bottom: 0.6rem;
        }

        .post-tldr {
            margin: 1.25rem 0 1.5rem;
            padding: 1rem 1.2rem;
            border-radius: 0.85rem;
            border: 1px solid rgba(43, 142, 255, 0.35);
            background: linear-gradient(135deg, rgba(43, 142, 255, 0.18), rgba(20, 24, 36, 0.9));
            box-shadow: 0 12px 24px rgba(0, 0, 0, 0.2);
        }

        .post-tldr-label {
            font-size: 0.8rem;
            letter-spacing: 0.18em;
            text-transform: uppercase;
            color: var(--accent-light);
            font-weight: 700;
            margin: 0 0 0.4rem;
        }

        .post-tldr p {
            margin: 0;
            line-height: 1.6;
            color: var(--text);
        }

        .post-block {
            display: grid;
            grid-template-columns: minmax(0, 1fr);
            gap: 1.5rem;
            align-items: start;
        }

        .post-body p {
            margin: 0 0 1rem;
            line-height: 1.7;
            color: var(--text);
        }

        .post-body strong {
            color: #fff;
        }

        .post-body ul {
            margin: 1rem 0 1.2rem;
            padding-left: 1.6rem;
        }

        .post-body li {
            margin: 0.4rem 0;
            line-height: 1.7;
            color: var(--text);
        }

        .pull-quote {
            margin: 1.5rem 0;
            padding: 1.1rem 1.4rem;
            border-radius: 0.9rem;
            border: 1px solid rgba(43, 142, 255, 0.35);
            background: linear-gradient(135deg, rgba(43, 142, 255, 0.14), rgba(20, 24, 36, 0.95));
            box-shadow: 0 14px 28px rgba(0, 0, 0, 0.25);
            font-style: italic;
            font-size: 1.05rem;
            line-height: 1.7;
            color: var(--text);
        }

        .pull-quote span {
            color: var(--accent-light);
            font-weight: 600;
        }

        figure {
            margin: 0;
        }

        img {
            width: 100%;
            border-radius: 0.75rem;
            display: block;
            border: 1px solid #262c3f;
        }

        figcaption {
            margin-top: 0.6rem;
            margin-bottom: 0.6rem;
            font-size: 0.9rem;
            color: var(--muted);
            text-align: center;
        }

        figure a {
            display: block;
        }

        .video-embed {
            position: relative;
            padding-top: 56.25%;
            margin: 1.5rem 0;
            border-radius: 0.75rem;
            overflow: hidden;
            border: 1px solid #262c3f;
        }

        .video-embed iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: 0;
        }

        .cta-row {
            margin-top: 1.5rem;
            display: flex;
            flex-wrap: wrap;
            gap: 0.8rem;
        }

        .cta {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            padding: 0.7rem 1.2rem;
            border-radius: 999px;
            background: var(--accent);
            color: #fff;
            font-weight: 600;
            transition: background 0.2s ease;
        }

        .cta:hover {
            background: var(--accent-light);
        }

        @media (max-width: 800px) {
            body {
                padding: 1.5rem;
            }

            .post {
                padding: 1.5rem;
            }

            .post-block {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <div class="nav">
            <a href="/blog/">&lt;- Back to blog</a>
            <a href="mailto:kyle@directiv.ai">Contact</a>
        </div>

        <h1 class="title">directiv.ai blog</h1>
        <p class="subtitle">
            Perspectives on building safe, controllable, AI-enabled applications
        </p>

        <article class="post">
            <h2 class="post-title">GenAI Isn't the Problem. Your Architecture Is.</h2>
            <div class="post-meta">January 25, 2026 - 10 min read</div>
            <div class="post-tldr">
                <div class="post-tldr-label">TL;DR</div>
                <p>Models propose, systems decide</p>
            </div>
            <div class="post-block">
                <div class="post-body">
                    <p>By now you've seen the <a
                            href="https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf">MIT
                            report from 2025</a> that claims
                        only ~5% of enterprise AI pilots deliver measurable business impact. The other 95% quietly
                        stall out or die on the vine.

                        The report points to many recurring reasons for those failures, here are a select few:</p>

                    <ul>
                        <li>AI tool integrations fail to fit cleanly into enterprise workflows in a way that delivers
                            real
                            value</li>
                        <li>GenAI solutions don't retain context or adapt to operational feedback in a way that
                            meaningfully
                            feeds back into the system</li>
                        <li>Most deployments boost individual productivity but fail to meaningfully change how systems
                            actually work</li>
                    </ul>

                    <p>I've seen these truths in my daily work, both as a user and as an engineer. But I don't think
                        these
                        problems stem from GenAI itself. I think these problems stem from probabalistic models being
                        dropped into deterministic workflows. The report states the following in it's final section:</p>
                    <blockquote class="pull-quote">
                        The most forward-thinking organizations are already experimenting with agentic systems that can
                        learn, remember, and act autonomously <span>within defined parameters</span>.
                    </blockquote>
                    <p>I think <em>within defined parameters</em> is doing a herculean amount of lifting in that
                        sentence. To explain what I mean, I need to tell you about the
                        Infinite
                        Improbability Drive.
                    </p>
                    <p>In <em>The Hitchhiker's Guide to the Galaxy</em>, the Infinite Improbability Drive is the core of
                        the Heart of Gold, the crew's interstellar spaceship. When activated the Infinite Improbability
                        Drive routinely causes wildly
                        improbable and chaotic events, like turning missiles into a whale and a bowl of petunias. It's a
                        notoriously unreliable and dangerous technology that can change the physical state of the ship
                        and its crew. And yet, it's also the component of the ship that makes instantaneous,
                        universe-bending jumps
                        possible. The rest of the ship surrounds the Infinite Improbability Drive
                        and provides
                        structure,
                        controls, and safety for its crew (most of the time).</p>

                    <div class="video-embed">
                        <iframe src="https://www.youtube.com/embed/BFSst3ujx6U" title="YouTube video player"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen></iframe>
                    </div>

                    <p>In your AI-enabled applications, an LLM plays the same role as the drive. It generates powerful,
                        probabilistic answers at incredible speed. Just like the Heart of Gold, the surrounding
                        application needs to provide
                        structure, controls, and safety for its users and admins. The LLM can
                        produce incredible results, but the LLM cannot own state, enforce rules,
                        or
                        safely recover from failure on its own. That responsibility belongs to the rest of the
                        application. When an LLM is narrowly focused inside of a system with
                        clear execution rules and
                        control points, you end up with something that might just actually provide value in production.
                    </p>

                    <p>In 2026, most enterprise GenAI application failures are not model-quality problems. They're
                        control-plane problems. Organizations are dropping probabilistic systems into workflows that
                        were built to be predictable and auditable without adding the architectural pieces to protect
                        the rest of the system from the new chaos.</p>

                    <p>If you want LLMs to play a core role in your systems, you must clearly separate
                        responsibilities. The model should be "just another API" inside a worflow, and the workflow
                        itself
                        owns execution, retries, and state transitions. Inputs, tool calls, outputs, and side effects
                        need to be versioned, replayable, and diffable.</p>

                    <p>An LLM's output should never mutate enterprise systems of record through indirect action (i.e.
                        LLM output
                        being forwarded to a system of record without policies) and certainly should not be allowed to
                        modify systems of record directly. It should only propose
                        actions. A governing orchestration layer decides what is allowed, enforces policy and
                        idempotency, and applies evaluation gates before anything mutates real systems.</p>

                    <p>This is where policy engines like <a href="https://www.openpolicyagent.org/">Open Policy
                            Agent</a> (OPA) are helpful. A well architected system with OPA can answer the following
                        questions using "old school" (no AI) techniques:</p>
                    <ul>
                        <li>Is this action allowed?</li>
                        <li>Does it require approval?</li>
                        <li>What constraints apply?</li>
                    </ul>
                    <p>Your policies should dictate the answers to those questions, not some clanker.</p>

                    <p>Every input, tool call, policy decision, and output should be written to an append-only run
                        ledger so executions are replayable and auditable. Models may suggest actions, and an
                        event-sourced/auditable execution system records not only what happened, but also records why
                        the actions happened. Side effects occur only through controlled
                        executors with idempotency keys so retries don't duplicate work. Higher-risk actions
                        can be routed through a human approval queue as a deliberate control.</p>

                    <p> All of this might sound like overkill, and in some AI-enabled applications this might not be
                        necessary. But the system around the LLM should be predictable where it matters for your use
                        case (e.g. state changes, side
                        effects, governance decisions). Once an LLM's output is captured as a
                        versioned input the orchestration, policy, and execution layers will behave the same way every
                        time. <em>The non-deterministic part of the system needs to end at the model
                            boundary.</em>
                        Once the LLM produces an output, that output should be treated as data. Not as ongoing behavior.
                    </p>

                    <figure>
                        <a href="../assets/llm-in-controlled-system.png" target="_blank" rel="noopener">
                            <img src="../assets/llm-in-controlled-system.png"
                                alt="LLM inside a controlled orchestration system with policy and logging" />
                        </a>
                        <figcaption>Models propose. Systems decide, execute, and record.</figcaption>
                    </figure>

                    <p>And yes, it's tempting to say “we'll just route all important decisions to a human.” That feels
                        safe, but that approach introduces its own failure modes. More on that in a future post.</p>

                    <p>GenAI feels wrong in many enterprises because it's being sprayed across workflows without
                        changing the underlying architecture. We're inserting probabilistic components into environments
                        that were designed for predictability, auditability, and control. Then we're pretending like
                        nothing else needs to change.</p>

                    <p>This isn't an AI maturity issue. It's a systems design failure. GenAI-enabled apps aren't
                        adapting well because we're
                        treating AI like the application itself, when it should be treated more like infrastructure.</p>

                    <p>The enterprise organizations getting this right aren't "using more AI." They're redesigning the
                        systems around
                        it. They're narrowing the use of AI to precise, value-adding features. These organizations
                        understand that
                        models should suggest data/actions, but the surrounding system must decide,
                        execute, and record.</p>

                    <p>To bring us back to the original point: one of the reasons enterprise GenAI integrations fail
                        is because we're treating these statistical engines like finished applications instead of
                        powerful components. Components that need to be contained, governed,
                        and integrated into real systems. When you design your architecture so the model proposes and
                        the system decides, GenAI-driven apps stop feeling chaotic and start
                        delivering
                        actual value. When the non-deterministic part of the system ends at the model boundary,
                        the technology might finally do what everyone hoped it
                        would in the first place.
                    </p>

                    <p>Said differently: get this right and you're the Heart of Gold. Get it wrong and you're the bowl
                        of petunias, with
                        just enough time for one last thought: "oh no, not again."</p>

                    <p>If you find yourself also thinking about these problems, let's nerd out. Drop me a line anytime
                        at
                        <a href="mailto:kyle@directiv.ai">kyle@directiv.ai</a>.
                    </p>

                </div>
            </div>
        </article>
    </div>
</body>

</html>